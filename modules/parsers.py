import re
import unicodedata
import subprocess
import json
import streamlit as st
import tempfile
import os

def parse_references_with_anystyle(raw_text):
    if not raw_text or not raw_text.strip():
        return [], []

    # ğŸ•µï¸ é›²ç«¯æŒ‡ä»¤åµæ¸¬é‚è¼¯
    # å˜—è©¦æ‰€æœ‰å¯èƒ½çš„æŒ‡ä»¤çµ„åˆ
    found_cmd = None
    test_cmds = [["anystyle", "--version"], ["ruby", "-S", "anystyle", "--version"]]
    
    for cmd in test_cmds:
        try:
            subprocess.run(cmd, capture_output=True, check=True)
            found_cmd = cmd[:-1] # ç§»é™¤ --version
            break
        except:
            continue

    if not found_cmd:
        st.error("âŒ ç„¡æ³•å•Ÿå‹•è§£æå¼•æ“ (AnyStyle)ã€‚è«‹å˜—è©¦ Manage App -> Rebootã€‚")
        return [], []

    lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
    structured_refs = []
    raw_texts = []
    
    progress_bar = st.progress(0)
    
    for i, line in enumerate(lines):
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', line))
        
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False, encoding="utf-8") as tmp:
            tmp.write(line)
            tmp_path = tmp.name

        # çµ„åˆè§£ææŒ‡ä»¤
        command = found_cmd + ["-f", "json", "parse"]
        if has_chinese and os.path.exists("custom.mod"):
            command += ["-P", "custom.mod"]
        command.append(tmp_path)

        try:
            result = subprocess.run(command, capture_output=True, text=True, encoding="utf-8", check=True)
            stdout = result.stdout.strip()
            
            # JSON æå–
            if "[" in stdout:
                stdout = stdout[stdout.find("[") : stdout.rfind("]")+1]
                data = json.loads(stdout)
                for item in data:
                    # ç°¡åŒ–ä½œè€…æ ¼å¼
                    if 'author' in item:
                        authors = []
                        for a in item['author']:
                            authors.append(f"{a.get('family', '')} {a.get('given', '')}".strip())
                        item['authors'] = "; ".join(authors)
                    
                    if 'text' not in item: item['text'] = line
                    structured_refs.append(item)
                    raw_texts.append(line)
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} ç­†è§£æå¤±æ•—: {str(e)}")
        finally:
            os.remove(tmp_path)
        
        progress_bar.progress((i + 1) / len(lines))
    
    return raw_texts, structured_refs
# ==============================================================================
# æ¨™é¡Œæ¸…æ´—å‡½å¼
# ==============================================================================

def clean_title(text):
    if not text:
        return ""
    text = unicodedata.normalize("NFKC", str(text))
    dash_chars = ["-", "â€“", "â€”", "âˆ’", "â€", "-"]
    for d in dash_chars:
        text = text.replace(d, "")
    cleaned = [
        ch.lower()
        for ch in text
        if unicodedata.category(ch)[0] in ("L", "N", "Z")
    ]
    return re.sub(r"\s+", " ", "".join(cleaned)).strip()

def clean_title_for_remedial(text):
    if not text:
        return ""
    text = unicodedata.normalize("NFKC", str(text))
    dash_chars = ["-", "â€“", "â€”", "âˆ’", "â€", "-"]
    for d in dash_chars:
        text = text.replace(d, "")
    text = re.sub(r"\b\d+\b", "", text)
    cleaned = [
        ch.lower()
        for ch in text
        if unicodedata.category(ch)[0] in ("L", "N", "Z")
    ]
    return re.sub(r"\s+", " ", "".join(cleaned)).strip()


